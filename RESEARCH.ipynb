{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "1. [Импорты и загрузки](#section1)\n",
    "2. [Предобработка и нормализация](#section2)\n",
    "3. [Работа с очищенными данными](#section3)\n",
    "4. [Bag-of-words модель](#section4)\n",
    "5. [RuBert Tiny 2 + FC](#section5)\n",
    "6. [KNNClassifier](#section6)\n",
    "7. [Итог](#section7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты и загрузки\n",
    "<a id = 'section1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import swifter # нужен для ускорения работы pandas\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from utils.ctfidf import CTFIDFVectorizer\n",
    "from utils.datasets import TextDataset, RuBertDataset\n",
    "from utils.models import BagOfWordsModel, RuBertClassifier\n",
    "from utils.utils import preprocess_text, train_model, test_model\n",
    "\n",
    "tqdm.pandas() # нужно для работы progress bar'ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex-utk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alex-\n",
      "[nltk_data]     utk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTEFACTS_PATH = './artefacts'\n",
    "DATASET_PATH = './dataset'\n",
    "SKLEARN_MODELS_PATH = './sclearn_saved_models'\n",
    "TORCH_MODELS_PATH = './models'\n",
    "\n",
    "N_CLASSES = 47\n",
    "\n",
    "# зададим random state\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# загрузка всего необходимого\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка и нормализация\n",
    "<a id = 'section2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# почистим и нормализуем данные\n",
    "data = pd.read_csv(f'{DATASET_PATH}/train.csv', sep=',')\n",
    "data = data.drop(columns=['id'])\n",
    "data['text'] = data['text'].swifter.apply(preprocess_text) # apply с прикрученым tqdm\n",
    "data.to_csv(f'{DATASET_PATH}/train_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>девятнадцатый арбитражный апелляционный суд по...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>двадцатый арбитражный апелляционный суд постан...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>шестой арбитражный апелляционный суд постановл...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>восемнадцатый арбитражный апелляционный суд по...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>седьмой арбитражный апелляционный суд постанов...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  девятнадцатый арбитражный апелляционный суд по...     20\n",
       "1  двадцатый арбитражный апелляционный суд постан...     12\n",
       "2  шестой арбитражный апелляционный суд постановл...      7\n",
       "3  восемнадцатый арбитражный апелляционный суд по...     23\n",
       "4  седьмой арбитражный апелляционный суд постанов...     17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка нормализованных данных\n",
    "data = pd.read_csv(f'{DATASET_PATH}/train_preprocessed.csv', sep=',')\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя сtf-idf (поклассовый tf-idf), выясним, какие слова наиболее часто встречаются в документах с соответствующими классами, возмем топ 10.\n",
    "\n",
    "\n",
    "Также выясним, топ 5000 слов с конца, которые являются бесполезными для нашей задачи классификации. Как правило это слова с ошибками, опечатками и просто ненужные нам (фамилии, бесполезный контекст и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для начала сгруппируем тексты по метке класса\n",
    "# лучше не запускать эту ячейку, так как ест очень много памяти\n",
    "# тут мы используем кастомный CTF-IDF класс\n",
    "data_grouped = data.groupby(['label'], as_index=False).agg({'text': ' '.join})\n",
    "\n",
    "count_vectorizer = CountVectorizer().fit(data_grouped['text'])\n",
    "count = count_vectorizer.transform(data_grouped['text'])\n",
    "\n",
    "ctfidf = CTFIDFVectorizer()\n",
    "ctfidf.fit(count, n_samples=105950) # 105950 - это размер трейновой выборки, захардкодил из-за ограничений памяти\n",
    "matrix = ctfidf.transform(count)\n",
    "\n",
    "# сохраним как артефакт, так как считается долго\n",
    "pickle.dump(ctfidf, open('sclearn_saved_models/ctfidf.pkl', 'wb'))\n",
    "pickle.dump(matrix, open('sclearn_saved_models/matrix.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 209602)\n",
      "(209602,)\n"
     ]
    }
   ],
   "source": [
    "# загрузим данные\n",
    "ctfidf = pickle.load(open('sclearn_saved_models/ctfidf.pkl', 'rb'))\n",
    "matrix = pickle.load(open('sclearn_saved_models/matrix.pkl', 'rb'))\n",
    "\n",
    "all_words = count_vectorizer.get_feature_names_out()\n",
    "print(matrix.shape)\n",
    "print(all_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним топ 10 самых важных по tf-idf слов в классе\n",
    "top_n = 50 \n",
    "labels = list(range(47))\n",
    "words_per_class = {label: all_words[matrix[label].toarray().argsort()[0,-top_n:]] for label in labels}\n",
    "with open(f'{ARTEFACTS_PATH}/best_{top_n}.txt', 'wt') as file:\n",
    "    for label, words in words_per_class.items():\n",
    "        file.write(f'{label}\\t{\", \".join(words)}\\n')\n",
    "       \n",
    "# сделаем тоже самое для топ 5000 самых мусорных слов\n",
    "worst_n = 5000\n",
    "words_per_class = {label: all_words[matrix[label].toarray().argsort()[0,:worst_n]] for label in labels}\n",
    "with open(f'{ARTEFACTS_PATH}/worst_{worst_n}.txt', 'wt') as file:\n",
    "    for label, words in words_per_class.items():\n",
    "        file.write(f'{label}\\t{\", \".join(words)}\\n')\n",
    "\n",
    "custom_stop_words = [words for _, words in words_per_class.items()]\n",
    "custom_stop_words = list(set(itertools.chain(*custom_stop_words)))\n",
    "\n",
    "pickle.dump(custom_stop_words, open(f'{ARTEFACTS_PATH}/custom_stop_words.pkl', 'wb'))\n",
    "print(f'Размер словаря бесполезных слов: {len(custom_stop_words)}')\n",
    "\n",
    "# таким образом можно почистить мусорные слова, полученные в результате ошибок/опечаток и просто ненужные нам,\n",
    "# но которые в норме не являются стоп словами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# почистим данные еще раз\n",
    "# не запускать, ячейка очень долго работает, ~7 часов\n",
    "custom_stop_words = pickle.load(open(f'{ARTEFACTS_PATH}/custom_stop_words.pkl', 'rb'))\n",
    "data = pd.read_csv(f'{DATASET_PATH}/train_preprocessed.csv', sep=',')\n",
    "\n",
    "def filter_stop_words(text):\n",
    "    tokens = text.split()\n",
    "    tokens = list(filter(lambda token: token not in custom_stop_words,\n",
    "                          tokens))\n",
    "    return ' '.join(tokens)\n",
    "data['text'] = data['text'].swifter.apply(filter_stop_words)\n",
    "data.to_csv(f'{DATASET_PATH}/train_no_stop_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проведем чистку тестовых данных аналогичным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babb5247178d434987ed57490962c2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# почистим и нормализуем данные\n",
    "test_data = pd.read_csv(f'{DATASET_PATH}/test.csv', sep=',')\n",
    "test_data = test_data.drop(columns=['id'])\n",
    "test_data['text'] = test_data['text'].swifter.apply(preprocess_text) # apply с прикрученым tqdm\n",
    "test_data.to_csv(f'{DATASET_PATH}/test_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с очищенными данными\n",
    "<a id = 'section3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# заметен очень сильный дизбаланс классов\n",
    "# micro prescision-recall может дать не самую точную метрику,\n",
    "# так как точность будет оцениваться в основном по самым частотным классам, более редкие\n",
    "# фактически будут иметь меньший вес\n",
    "train_data = pd.read_csv('train_no_stop_words.csv')\n",
    "train_data.loc[:, 'label'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words модель\n",
    "<a id = 'section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем простую модель с bag-of-words подходом и несколькими полносвязаными слоями.\n",
    "\n",
    "Закодируем тестовую и трейн выборку при помощи CountVectorizer и полученные вектора будем использовать для обучения классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# еще один, гораздо более быстрый способ фильтрации мусорных слов - задать min_df порог,\n",
    "# отсеивающий слишком редкие и бесполезные слова\n",
    "# размер словаря: был - 187615, стал - 14755\n",
    "train_data = pd.read_csv('train_no_stop_words.csv')\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0.0003) # наиболее оптимальный порог\n",
    "vectorizer.fit(train_data['text'])\n",
    "pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))\n",
    "\n",
    "train_data['text'] = train_data['text'].progress_apply(lambda text: vectorizer.transform([text]))\n",
    "train_data = train_data.rename(columns={'text': 'features'})\n",
    "train_data.to_pickle(f\"{DATASET_PATH}/train_data_encoded.pkl\")\n",
    "\n",
    "# посмотрим на слова, которые у нас сохранились и\n",
    "# будут использоваться для кодирования\n",
    "lst = list(vectorizer.get_feature_names_out())\n",
    "with open(f'{ARTEFACTS_PATH}/final_dict.txt', 'wt') as file:\n",
    "    for word in lst:\n",
    "        file.write(f'{word}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(f'{SKLEARN_MODELS_PATH}/vectorizer.pkl', 'rb'))\n",
    "data = pd.read_pickle(f'{DATASET_PATH}/train_data_encoded.pkl')\n",
    "\n",
    "# Разбиение на трейн и валидацию\n",
    "train_set, val_set = train_test_split(data, test_size=0.1, random_state=42,\n",
    "                                      stratify=data['label']) # обязательно стратификацию\n",
    "\n",
    "train_data = TextDataset(train_set)\n",
    "val_data = TextDataset(val_set)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=23838, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=10595, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "\n",
    "model = BagOfWordsModel(embed_dim=len(vectorizer.get_feature_names_out()), # 14755\n",
    "                        num_class=N_CLASSES) \n",
    "model.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "sheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.CrossEntropyLoss"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "train_model(model, train_loader, val_loader, criterion, sheduler,\n",
    "            optimizer, n_epochs, f'{TORCH_MODELS_PATH}/BagOfWords.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfWordsModel(\n",
       "  (fc1): Linear(in_features=14755, out_features=300, bias=True)\n",
       "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (fc4): Linear(in_features=100, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка обученной модели\n",
    "model.load_state_dict(torch.load(f'{TORCH_MODELS_PATH}/BagOfWords.pt'))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1952/1952 [00:01<00:00, 1130.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Подготовка тестовой части\n",
    "test_data = pd.read_csv(f'{DATASET_PATH}/test_preprocessed.csv')\n",
    "\n",
    "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
    "\n",
    "test_data['text'] = test_data['text'].progress_apply(lambda text: vectorizer.transform([text]))\n",
    "test_data = test_data.rename(columns={'text': 'features'})\n",
    "\n",
    "test_dataset = TextDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность - 0.7694672346115112\n",
      "Полнота - 0.7694672346115112\n"
     ]
    }
   ],
   "source": [
    "# Оценка метрик\n",
    "precision, recall = test_model(model, test_loader, n_classes=47)\n",
    "print(f'Точность - {precision}') \n",
    "print(f'Полнота - {recall}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RuBert Tiny 2 + FC\n",
    "<a id = 'section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном подходе попробуем использовать дистиллированый [rubert-tiny-2](https://huggingface.co/cointegrated/rubert-tiny2).\n",
    "\n",
    "Будем получать эмбеддинги всего текста и использовать их с полносвязным слоем для получения класса.\n",
    "\n",
    "В ходе эскпериментов понял, что больше одного слоя делать не очень, так как лосс очень плохо сходится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 2048, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 312, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве энкодера текстов используем rubert-tiny2\n",
    "# будем кодировать текст в вектор и пытаться с помощю одного fc слоя прдетсказывать класс\n",
    "\n",
    "encoder = SentenceTransformer('cointegrated/rubert-tiny2')\n",
    "encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105950/105950 [1:29:43<00:00, 19.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# переведем тексты в эмбеддинги и сохраним\n",
    "# ячейка долго выполняется!\n",
    "\n",
    "tqdm.pandas()\n",
    "train_data = pd.read_csv(f'{DATASET_PATH}/train_no_stop_words.csv')\n",
    "train_data['text'] = train_data['text'].progress_apply(lambda text: encoder.encode(text))\n",
    "train_data = train_data.rename(columns={'text': 'features'})\n",
    "train_data.to_pickle(f\"{DATASET_PATH}/train_data_rubert.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим нашу сетку правильно классифицировать тексты по эмбеддингам rubert размерности 312\n",
    "data = pd.read_pickle(f\"{DATASET_PATH}/train_data_rubert.pkl\")\n",
    "\n",
    "train_set, val_set = train_test_split(data, test_size=0.1, random_state=42,\n",
    "                                      stratify=data['label']) # обязательно стратификацию\n",
    "\n",
    "train_data = RuBertDataset(train_set)\n",
    "val_data = RuBertDataset(val_set)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=95355, shuffle=True, num_workers=10, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=10595, shuffle=True, num_workers=10, drop_last=True)\n",
    "\n",
    "\n",
    "model = RuBertClassifier(embed_dim=312, # выход rubert-2-tiny\n",
    "                         num_class=N_CLASSES)\n",
    "model.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "sheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "\n",
    "n_epochs = 10000\n",
    "train_model(model, train_loader, val_loader, criterion, sheduler, optimizer,\n",
    "            n_epochs, f'{TORCH_MODELS_PATH}/RuBertClassifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1952/1952 [01:42<00:00, 19.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Подготовка тестовой части\n",
    "test_data = pd.read_csv(f'{DATASET_PATH}/test_preprocessed.csv')\n",
    "\n",
    "test_data['text'] = test_data['text'].progress_apply(lambda text: encoder.encode(text))\n",
    "test_data = test_data.rename(columns={'text': 'features'})\n",
    "test_data.to_pickle(f\"{DATASET_PATH}/test_data_rubert.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RuBertClassifier(\n",
       "  (fc1): Linear(in_features=312, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка уже обученной модели\n",
    "model = RuBertClassifier(embed_dim=312, # выход rubert-2-tiny\n",
    "                         num_class=N_CLASSES)\n",
    "model.load_state_dict(torch.load(f'{TORCH_MODELS_PATH}/RuBertClassifier.pt'))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность - 0.655225396156311\n",
      "Полнота - 0.655225396156311\n"
     ]
    }
   ],
   "source": [
    "# Оценка метрик\n",
    "test_data = pd.read_pickle(f\"{DATASET_PATH}/test_data_rubert.pkl\")\n",
    "test_dataset = RuBertDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "precision, recall = test_model(model, test_loader, n_classes=N_CLASSES)\n",
    "print(f'Точность - {precision}') \n",
    "print(f'Полнота - {recall}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNClassifier\n",
    "<a id = 'section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучиться простой KNN классификатор на эмбеддингах из ru-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(f\"{DATASET_PATH}/train_data_rubert.pkl\")\n",
    "train_x, train_y = np.stack(train_data['features']), train_data['label']\n",
    "\n",
    "test_data = pd.read_pickle(f\"{DATASET_PATH}/test_data_rubert.pkl\")\n",
    "test_x, test_y = np.stack(test_data['features']), test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 17, 'weights': 'distance'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определим наиболее оптимальные параметры и посмотрим их\n",
    "params = { \n",
    "    'n_neighbors': np.arange(15, 23, dtype=int),\n",
    "    'p': [1, 2, np.inf], # манхеттенская, евклидова метрика и расстояние чёбышева\n",
    "    'weights': ['uniform', 'distance'] \n",
    "}\n",
    "\n",
    "scoring = ['precision_micro', 'recall_micro']\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), params,\n",
    "                           scoring=scoring, refit='precision_micro', n_jobs=12)\n",
    "grid_search.fit(train_x, train_y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность - 0.6480532786885246\n",
      "Полнота - 0.6480532786885246\n"
     ]
    }
   ],
   "source": [
    "# теперь возмем полученные параметры и обучим на них классификатор\n",
    "# учится быстро\n",
    "knn = KNeighborsClassifier(n_neighbors=20, p=2,\n",
    "                           n_jobs=-1, weights='distance')\n",
    "knn.fit(train_x, train_y)\n",
    "pred_y = knn.predict(test_x)\n",
    "\n",
    "print(f'Точность - {precision_score(test_y, pred_y, average=\"micro\")}') \n",
    "print(f'Полнота - {recall_score(test_y, pred_y, average=\"micro\")}')\n",
    "\n",
    "# Точность - 0.6480532786885246\n",
    "# Полнота - 0.6480532786885246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог\n",
    "<a id = 'section7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                     | Точность           | Полнота            |\n",
    "|---------------------|--------------------|--------------------|\n",
    "| Bag-of-words модель | 0.7694672346115112 | 0.7694672346115112 |\n",
    "| RuBert Tiny 2 + FC  | 0.6552253961563110 | 0.6552253961563110 |\n",
    "| KNNClassifier       | 0.6480532786885246 | 0.6480532786885246 |\n",
    "\n",
    "По итогу вышло, что наиболее простой подход с bag-of-words выдал лучший скор. Возможно, что использование более мощного энкодера вместо самого маленького RuBert дало бы результат лучше, но не хватило вычислительных мощностей.\n",
    "\n",
    "В дальнейшей работе наилучшу модель имеет смысл конвертировать в onnx и заинференсить в Nvidia Triton Inference Server для более быстрой работы и поддержки динамического батчинга."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tz_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
